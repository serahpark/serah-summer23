{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65cae0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Net', 'income', 'was', '$', '9.4', 'million', 'compared', 'to', 'the', 'prior', 'year', 'of', '$', '2.7', 'million', '.']\n",
      "<class 'str'>\n",
      "['Revenue', 'exceeded', 'twelve', 'billion', 'dollars', ',', 'with', 'a', 'loss', 'of', '$', '1b', '.']\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = list(nlp.pipe(texts))\n",
    "for doc in nlp.pipe(texts):\n",
    "    # Do something with the doc here\n",
    "    print([token.text for token in doc])\n",
    "    print(type(([token.text for token in doc])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1424100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net income was $9.4 million compared to the prior year of $2.7 million.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254d2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de47662a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, spacy.tokens.token.Token found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a dictionary representation of the documents.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m \u001b[43mDictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Filter out words that occur less than 20 documents, or more than 50% of the documents.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dictionary\u001b[38;5;241m.\u001b[39mfilter_extremes(no_below\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, no_above\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/corpora/dictionary.py:78\u001b[0m, in \u001b[0;36mDictionary.__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_nnz \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m documents \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprune_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprune_at\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m         msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_docs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents (total \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m corpus positions)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/corpora/dictionary.py:204\u001b[0m, in \u001b[0;36mDictionary.add_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    201\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madding document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, docno, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# update Dictionary with the document\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc2bow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_update\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ignore the result, here we only care about updating token ids\u001b[39;00m\n\u001b[1;32m    206\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilt \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m documents (total \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m corpus positions)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_docs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_pos)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/gensim/corpora/dictionary.py:246\u001b[0m, in \u001b[0;36mDictionary.doc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    244\u001b[0m counter \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m document:\n\u001b[0;32m--> 246\u001b[0m     counter[w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    248\u001b[0m token2id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken2id\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_update \u001b[38;5;129;01mor\u001b[39;00m return_missing:\n",
      "\u001b[0;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, spacy.tokens.token.Token found"
     ]
    }
   ],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90380ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
